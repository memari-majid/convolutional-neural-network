{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvNet-implement-001.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-5KM3v7WQZ_dMhjjDsRR21ObGswBNUyb",
      "authorship_tag": "ABX9TyORp4+t9vDS888vINhxmHej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/memari-majid/convolutional-neural-network/blob/main/ConvNet_implement_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D ConvNet\n",
        "Naive Convolution Implementation"
      ],
      "metadata": {
        "id": "WBCE6wwjbLGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8yrN2gw_iah7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifpK3cc8whxY",
        "outputId": "d649e6a4-6535-4a2c-886a-089aa23a76f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing  \n",
        "* Grayscale image = 2-d Conv\n",
        "* When reading images with **OpenCV**, the default mode is **BGR** and not **RGB**, so we will specify the code parameter as BGR2GRAY, allowing us to turn the BGR image into a grayscaled image. "
      ],
      "metadata": {
        "id": "dRVvEx7difXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading image\n",
        "image = cv2.imread('/content/drive/MyDrive/Notebooks/Coding/image.jpeg') \n",
        "print(f'image shape RGB = {image.shape}')\n",
        "# converting BGR to Graysclae\n",
        "image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY) \n",
        "print(f'image shape Grayscale = {image.shape}')"
      ],
      "metadata": {
        "id": "lfiKTu24j3JE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc50893a-5074-4370-ab73-5e43aede4138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape RGB = (359, 638, 3)\n",
            "image shape Grayscale = (359, 638)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Edge Detection Kernel\n",
        "kernel = np.array([[-1, -1, -1], \n",
        "                   [-1, 8, -1], \n",
        "                   [-1, -1, -1]])\n",
        "print(kernel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oco2-toTtgdk",
        "outputId": "3b68ba53-0b4f-4fbb-aa4d-0d110ecafa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1 -1 -1]\n",
            " [-1  8 -1]\n",
            " [-1 -1 -1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CV2 uses Cross Correlation = flipped Convolution \n",
        "* Need to **flipp** the matrix horizontally then vertically"
      ],
      "metadata": {
        "id": "FjWkByDbvl85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flipped Cross Correlation = Convolution\n",
        "kernel = np.flipud(np.fliplr(kernel))\n",
        "print(kernel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6abwyScuzOo",
        "outputId": "340938a5-3ce8-4cdc-cf62-db74e9652540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1 -1 -1]\n",
            " [-1  8 -1]\n",
            " [-1 -1 -1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Shape\n",
        "xImgShape = image.shape[0]\n",
        "yImgShape = image.shape[1]"
      ],
      "metadata": {
        "id": "7ixcxYUlwC7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel Shape\n",
        "xKernShape = kernel.shape[0]\n",
        "yKernShape = kernel.shape[1]"
      ],
      "metadata": {
        "id": "Zi6AFsY2x8E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding Size\n",
        "padding = 2\n",
        "# Default Strides Size\n",
        "strides = 1"
      ],
      "metadata": {
        "id": "JupvqCT7xqp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We multiply the padding by 2 because we are applying even padding on all sides so a padding of 1 would increase the dimension of the padded image by 2.\n"
      ],
      "metadata": {
        "id": "5DxBhxLG3NRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conv Output Shape\n",
        "xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
        "yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
        "output = np.zeros((xOutput, yOutput))\n",
        "print(f' output shape = {output.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er2MaT95wFII",
        "outputId": "dbe1458d-ea0b-4d99-cb61-0a90bea119e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " output shape = (361, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Equal Padding to All Sides\n",
        "if padding != 0:\n",
        "    # adding 2 padding to X and Y\n",
        "    imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
        "    # replacing the inner portion of the padded image with the image\n",
        "    # nd array slicing [padding:-padding] = [1:-1]\n",
        "    imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n",
        "    print(f'Padded Image Shape = {imagePadded.shape}')\n",
        "    print(imagePadded)\n",
        "else:\n",
        "    imagePadded = image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iazzF6mGwIKf",
        "outputId": "489fc88b-8483-412b-eb2c-d577db86140a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Image Shape = (363, 642)\n",
            "[[ 0.  0.  0. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]\n",
            " [ 0.  0. 78. ... 44.  0.  0.]\n",
            " ...\n",
            " [ 0.  0. 40. ... 17.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution \n",
        "* iterate through the image \n",
        "* element wise multiplication\n",
        "* sum"
      ],
      "metadata": {
        "id": "vBW2p-E6574S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through columns\n",
        "for y in range(image.shape[1]):\n",
        "    # stop when y out of kernel size\n",
        "    if y > image.shape[1] - yKernShape:\n",
        "        break\n",
        "    # Y must be divisble by strides\n",
        "    if y % strides == 0:\n",
        "        for x in range(image.shape[0]):\n",
        "            # stop when x out of kernel size\n",
        "            if x > image.shape[0] - xKernShape:\n",
        "                break\n",
        "            try:\n",
        "                # X must be divisble by strides\n",
        "                if x % strides == 0:\n",
        "                  # slicing[x:kernel size] slicing[y:kernel size]\n",
        "                  output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n",
        "            except:\n",
        "                break"
      ],
      "metadata": {
        "id": "pSQWT9V9DEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imwrite('2DConvolved.jpg', output)\n",
        "'2DConvolved.jpg'"
      ],
      "metadata": {
        "id": "etqkVIjowP9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15499e2c-cddd-4049-8004-ade9d247b0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2DConvolved.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}